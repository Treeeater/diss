\chapter[The Explication Process] {The Explication Process\footnote{The contents of this chapter is based on the paper: Explicating SDKs: Uncovering Assumptions Underlying Secure Authentication and Authorization~\cite{explicatingSDKs}.}}
\label{sec:explication}

In this Chapter and Chapter~\ref{sec:ssoscan}, we consider the scenario where the third-party service provider is benign and works with the host, but the integrated service implements security-critical functionality of the system, such as authentication and authorization. 

Implementing secure authentication is an important requirement for any modern application that interacts with its users.  Even when the application's native authentication (traditional user name and password log in) is secure, integrating third-party SSO services may significantly complicates the situation.  Recent years, many researchers have done work to find vulnerabilities in such integrations, however, no previous study has rigorously examined the security properties these SDKs provide to real-world applications.  Typically, SDK providers simply release SDK code, publish related documentation and examples, and leave the rest to the app developers.  An important question remains: if developers use the SDKs in reasonable ways, will the resulting applications be secure?  We show in this chapter that the answer today is \emph{No}.  The majority of apps built using the SDKs we studied have serious security flaws.  In addition to direct vulnerabilities in the SDK, many flaws exists because achieving desired security properties by using an SDK depends on many implicit assumptions that are not readily apparent to app developers. These assumptions are not documented anywhere in the SDK or its documentation. In several cases, even the SDK providers are unaware of these assumptions.

This motivates us to develop a more systematic approach --- \emph{the explication process}, through which we hope to offer more confidence to the service provider and the application developer that no missing assumptions or vulnerabilities are left behind.  The goal of this work is to systematically identify the assumptions needed to securely integrate the SDK.  We emphasize that it is not meaningful to verify an SDK by itself.  Instead, our goal is to explicate the assumptions upon which secure use of the SDK depends.  We do this by devising precise definitions of desired security properties, constructing an explicit model of the SDK and the complex services with which it interacts, and systematically exploring the space of applications that can be built using the SDK.  Our approach involves a combination of manual effort and automated formal verification.  Any counterexample found by the verification tool indicates either (1) that our system models are not accurate, in which case we revisit the real systems to correct the model; or (2) that our models are correct, but additional assumptions need to be captured in the model and followed by application developers.  The explication process is an iteration of the above steps so that we document, examine and refine our understanding of the underlying systems for an SDK.  At the end, we get a set of formally captured assumptions and a semantic model that allow us to make meaningful assurances about the SDK: an application constructed using the SDK following the documented assumptions satisfies desired security properties.

We argue that the explication process should be part of the engineering effort of developing an SDK.  Newly discovered security-critical assumptions through this process can either be dismissed by modifying the SDK (the preferable solution), or be documented precisely.

For the rest of this chapter, we first discuss prior works in more details in Chapter~\ref{sec:explicating_prior_works}.  We then describe an illustrative missing implicit assumption example in Chapter~\ref{sec:explicating_illustrative_example}, how the iterative explication process works in Chapter~\ref{sec:explicating_explication_process}, how various parts of the system are modeled in Chapter~\ref{sec:explicating_semantic_modeling}, and finally the implicit assumptions we uncovered using this approach on Facebook and Microsoft's SSO services in Chapter~\ref{sec:explicating_discoveries} and their exploit opportunities in Chapter~\ref{sec:explicating_exploit_opportunities}.

\section{Prior Works}
\label{sec:explicating_prior_works}

The idea of formally verifying properties of software systems goes back to Alan Turing, although it only recently became possible to automatically verify interesting properties of complex, large scale systems.  The explication process makes use of considerable advances in model checking that have enabled model checkers to work effectively on models as complex as the ones we use here.  This approach is most closely related to other work on inferring and verifying properties of interfaces such as APIs and SDKs, which are briefly reviewed next.

\subsection{API and SDK Misuses}

It is no longer a mystery that APIs and SDKs can be misunderstood and the results often include security problems.  On various UNIX systems, \emph{setuid} and other related system calls are non-trivial for programmers to understand.  Chen et al. ``demystified'' (that is, explicated) these functions by comparing them on different UNIX versions and formally modeling these system calls as transitions in finite state automata~\cite{Chen:2002:SD:647253.720278}.  Wang et al.~\cite{Wang:2011:SFO:2006077.2006782,Wang:2012:SMY:2310656.2310691} showed logic bugs in how websites integrate third-party cashier and SSO services.  Many of the bugs found appear to result from website developers' confusions about API usage. Georgiev et al.~\cite{Georgiev:2012:MDC:2382196.2382204} showed that SSL certificate validations in many non-browser applications are broken, which make the applications vulnerable to network man-in-the-middle attacks.  Our work started from a different perspective --- our primary goal is not to show that SDKs can be misused, but to argue that these misuses are so reasonable that it is SDK providers' lapse not to explicate the SDKs to make their assumptions clear.  We expect that our approach could be adapted to other contexts such as third-party payment and SSL certificate validation. 

\subsection{Program and Interface Verification}

Various techniques have been proposed to help automatically verify certain program properties regarding library interfaces.  Spinellis and Louridas~\cite{Spinellis:2007:FSV:1244490.1244957} built a static analysis framework for verifying Java API calls.  Library developers are required to write imperative checking code for each API to assist the verification process.  Henzinger et al.~\cite{deAlfaro:2001:IA:503209.503226,Beyer:2005:WSI:1060745.1060770} worked on a set of languages and tools to help model the interfaces and find assumptions that need to be met for two APIs to be \emph{compatible}.  The compatibility check is performed by computing compatible states, which amounts to solving a game between the product automaton (which tries to enter illegal states) and its environment (which tries to prevent this).  JIST~\cite{Alur:2005:SIS:1040305.1040314} infers necessary call sequences given a class and an exception property for Java, so that the exception is never raised.  Our proposed work has similar goals but is more focused on the study of details of complex real-world integrated systems and developing a systematic approach to analyze them.  We do not assume source code access from the system.  For example, our work involves probing and summarizing semantics for various parts of the SSO system including the device runtime, identity provider back end server, and application back end server.

Several works have automatically inferred program invariants or specifications.  Daikon~\cite{ErnstGKN99,Ernst2000:PhD,ErnstCGN2001:TSE} automatically learns program invariants of variables (strings, certain data structures, etc.) by instrumenting the program, running test cases, collecting and analyzing program traces.  Felmetsger et al.~\cite{Felmetsger:2010:TAD:1929820.1929834} applies Daikon to web applications to detect logic vulnerabilities.  Yang and Evans~\cite{Yang:2004:DIT:996821.996832, Yang:2006:PMT:1134285.1134325} proposed approaches to discover temporal invariants by analyzing execution traces.  Weimer et al.~\cite{Weimer05miningtemporal,LeGoues:2012:MCQ:2122269.2122550} proposed automated and generic ways to mine temporal specifications based on the assumption that certain parts of the program are more error-prone than others, such as code with poor readability or traces that raise exceptions.  Sekar~\cite{DBLP:conf:ndss:Sekar09} does approximate string comparison to infer input/output relationship between web application requests and responses to help eliminate code injection attacks.  Such inference techniques generally require a large number of execution traces, as well as that the majority of them are correct.  This assumption is not necessarily true in our problem.  

\subsection{OAuth Protocol Analysis}
Bansal et al.~\cite{6266164} modeled OAuth 2.0 protocol and verified it using ProVerif~\cite{Blanchet:2001:ECP:872752.873511}.  They also built a library for future researchers to model web APIs into ProVerif language in a easier fashion.  Pai et al.~\cite{5966531} used Alloy framework~\cite{Alloy} to verify OAuth 2.0 and discovered a previously known vulnerability.  Sun et al.~\cite{Sun:2012:DDE:2382196.2382238} discussed a number of website problems affecting OAuth's effectiveness, such as not using HTTPS, having cross-site scripting and cross-site request forgery bugs.  The fact that both SSO services we studied are based on OAuth is mainly because of its widespread adoption, but the security issues we found concern the SDK and service implementations, rather than flaws inherent in the OAuth protocol.  

\section{An Illustrative Example}
\label{sec:explicating_illustrative_example}

To motivate our work, we describe a simple example in the context of the Microsoft Live Connect (Microsoft's Single Sign-On service). It illustrates what can go wrong when SDKs are provided without thoroughly specifying their underlying security assumptions.   

\subsection{Intended Use}

To start things from scratch, we assume the developer has no previous experience with such implementation.  The most reasonable first thought is to visit the developer guide\footnote{Information accurate as of April 2014} for Microsoft Live~\cite{LiveConnectDoc}.  This page provides code snippets in JavaScript, C\#, Objective-C and Java showing how to use Live Connect SDK to sign users into a client app.  Ignoring the irrelevant details, we generalize the code snippets to the authentication logic shown in Figure~\ref{fig:live_access_token}.

\begin{figure}[hbt]
\centering
\includegraphics[width=.5\textwidth]{figures/chapter3/live_access_token}
\caption{Documented Microsoft Live Connect authentication logic}
\label{fig:live_access_token}
\end{figure}

In the figure, WL stands for Windows Live. A developer first needs to call \code{WL.login} defined in the JavaScript SDK. The call takes an argument value ``wl.basic'', indicating that the app will need to read the user's basic information after the function returns an \emph{access\_token} in step (2).  The \emph{access\_token} is the same as described earlier in Chapter~\ref{sec:bg_sso_protocol}.  Once the app obtains the \emph{access\_token}, it calls another function, shown in step (3), to get the user's basic information.  The call is essentially equivalent to issuing an HTTP request to the following URL:

\setlength{\fboxrule}{0pt}
\fbox{\parbox[c][4em][c]{\textwidth}{\url{https://apis.live.net/v5.0/me?access_token=ACCESS_TOKEN}} }

The Live ID service responds with the user's name and Microsoft Live ID in the message in step (4). This completes the process, authenticating the user with the provided information. 

\subsection{Unintended (Hazardous) Use}

The developer guide as depicted in Figure~\ref{fig:live_access_token} is valid for a client-only application, but it is not clear that the same logic must not be used with an application that also incorporates an online service.  Without stating this explicitly, developers may be inclined to use the SDK insecurely as shown in Figure~\ref{fig:live_access_token_2}. The interactions with the Live ID service are identical in the two figures.  The only difference is that in the second scenario, the \emph{access\_token} is sent back to the back-end server of the application in step (2a) and it is the app server that makes the REST API call to retrieve user information and authenticate. 

\begin{figure}[hbt]
\centering
\includegraphics[width=.5\textwidth]{figures/chapter3/live_access_token_2}
\caption{Vulnerable Microsoft Live Connect authentication logic}
\label{fig:live_access_token_2}
\end{figure}

This can lead to a serious vulnerability that allows any application on the device to sign into the app server as the user. A rogue app may send a legitimate request to the Live ID service for an \emph{access\_token} to view public information of the victim, and the user granted the requested information without suspicion.  The problem is this token, obtained by the rogue app and intended for authorizing access to the user's resource, can be abused and sent to the vulnerable application's back-end server from the rogue app developers to perform an impersonation attack.  Since the vulnerable app's server never checks which application the \emph{access\_token} is issued for, it would happily accept the token from rogue app developers and authenticate them as the victim.  A quick search on the app market reveals that this mistake is fairly common in real world applications.  In addition, although we first observed it when analyzing the Live Connect documentation, we later found that many apps using the Facebook SDK suffer from the same issue.  

\subsection{Resolution and Insights}

From one perspective, this is simply a matter of developers writing buggy apps, and the blame for the security vulnerability rests with the app developers.  We argue, though, that the purpose of the SDK is to enable average developers to produce applications that achieve desired security properties by default, and the prevalence of buggy apps created using this SDK indicates a failure of the larger engineering process.  The developer exercised reasonable prudence by using the \emph{access\_token} to query the ID service for user information and followed exactly the process described in the SDK's documentation (Figure~\ref{fig:live_access_token}).  The problem is a lack of deeper understanding of the difference between authentication and authorization, and the role of the \emph{access\_token} (i.e., why it is safe to use the \emph{access\_token} as shown in Figure~\ref{fig:live_access_token} but not in Figure~\ref{fig:live_access_token_2}).  Correct usage depends on subtle understanding of what kind of evidence each message represents and whether or not the whole message sequence establishes an effective proof for a security decision.  It is unrealistic to expect an average developer to understand these subtleties, especially without a clear guidance from the SDK.

We contacted the developers of some of the vulnerable apps. A few apps have been fixed in response to our reports.  We also notified the OAuth Working Group in June 2012 about these vulnerable apps\footnote{Subsequently, we learned that John Bradley, a working group member, had posted a blog post in January 2012 about a similar issue~\cite{OAuthVulBlogPost}. The post considers the problem a vulnerability of the protocol, while we view it as a consequence of an unclear assumption about SDK usage because there are correct ways to use OAuth for service authentication}.  Dick Hardt, one of the editors of OAuth 2.0 specification (RFC 6749)~\cite{OAuth2.0}, emailed us requesting a paragraph to be included in the specification to address this issue.  We proposed the initial text and discussed with working group members.  This has resulted in Section 10.16 ``Misuse of \emph{access\_token} to Impersonate Resource Owner in Implicit Flow'' being added to the specification.

The key point we want to get across in this example is that security of applications constructed with an SDK depends on an understanding of the external service offered by the SDK provider, as well as subtleties in the use of tokens and assumptions about evidence used in authentication and authorization decisions.  We believe the prevalence of vulnerable apps constructed using current SDKs yield compelling evidences that a better engineering process is needed, rather than just passing the blame to overburdened developers.  This motivates us to advocate for a process that explicates SDKs by systematically identifying the underlying assumptions upon which secure usage depends.

\section{The Explication Process}
\label{sec:explicating_explication_process}

In order to explicate the SDKs, we need to clearly define the desired security properties. This Chapter introduces our target scenario and threat model, and then defines the desired security properties and gives an overview about the explication process for uncovering implicit SDK assumptions.

\subsection{Scenario}

A typical question about security is whether some property holds for a system, even in the presence of an adversary interacting with the system in an unconstrained manner.  Such problems are often tackled by modeling a concrete target system and an \emph{abstract} adversary (i.e., a test harness in software testing terminology) that explores all interaction sequences with the concrete system.  In our scenario, however, the target system is not even concrete.  We wish to reason about all applications that can be built with the SDK following documented guidelines.  Hence, we need to consider both the application's client and server components as abstract modules.

\begin{figure}[hbt]
\centering
\includegraphics[width=.7\textwidth]{figures/chapter3/system_modules}
\caption{Parties and Components in the SSO Process}
\label{fig:system_modules}
\end{figure}

Without mingling in the threat model, Figure~\ref{fig:system_modules} illustrates the three parties involved in an SSO process. There are three main components: application client on the left, application server on the right, and the identity provider on the bottom.  Both the client and server applications are abstract modules, and they can be further divided into three layers.  

The bottommost layer represents all the client runtime, e.g. the browser or application VM.  Special attention has to be exercised when learning and modeling this layer.  These are complex modules that an outsider researcher typically does not understand in detail in the beginning of the study.  Developing a semantic model for these components involves substantial system investigation effort (as described in Section~\ref{sec:explicating_semantic_modeling}) because the seemingly clear SDK behavior running on top (even with source code available) actually depends a lot on this mysterious (and often incompletely documented) underlying runtime.  We consider the formal semantic models resulting from this study as one of the main contributions of this work.

Assuming the developer always integrates the IdP-provided SDK for authentication and authorization, the middle layer consists of such SDKs, which we often have source code access to.  These are relatively easy to learn and model compared to the rest of the layers.

On top of these two layers lies the application code --- FooApp\textsubscript{C} and FooApp\textsubscript{S} for client and server component respectively.  We assume that FooApp\textsubscript{C} and FooApp\textsubscript{S} do not directly interact with the service runtime except via the middle layer SDK.  Note that if the IdP receives a call from either of these components, it has no reliable way to tell if the caller is a client device or an application server.  FooApp\textsubscript{C} and FooApp\textsubscript{S} belong to the \emph{abstract but restricted} module type:  At modeling time, they do not have concrete implementations, and our goal is to reason about all possible apps built on top of the other two layers; nevertheless, the app modules do have constraints on their behaviors: we assume their developers are reasonable and therefore the modules must not violate the rules documented in the existing SDK developer guides.

\subsection{Threat Model}

\begin{figure}[hbt]
\centering
\includegraphics[width=.7\textwidth]{figures/chapter3/explicating_threat_model}
\caption{Threat Model in the SSO Process}
\label{fig:explicating_threat_model}
\end{figure}

We assume a malicious application, MalApp\textsubscript{C} shown in Figure~\ref{fig:explicating_threat_model}, may be installed and ran on the victim's device.  This can be done by either offering an incentive or masquerading as another popular benign application.  For the malicious application, its behavior is not constrained by the client SDK, therefore it is closer to be a fully abstract module, only to be limited by the functionalities provided by the client device runtime (e.g., it cannot access cookies of other domains or access restricted files).  In addition, the attacker also controls an unconstrained external machine, which we call ``Mallory''. Readers can think of Mallory as a combination of a client and server that can freely initiate communication with all the rest parties. 

\subsection{Security Properties}
\label{sec:security_properties}
A precise understanding of the security properties that an integrated service should provide is essential for explicating the SDK: they determine which assertions should be added to the model.  We have identified several general principles of security property with respect to third-party services: 1) \emph{verification} --- a secret or signature needs to be verified before it is trusted; 2) \emph{secrecy} --- user credentials or application secrets must not be leaked through any API calls; 3) \emph{consistency} --- bindings of user data must be consistent across transactions; and 4) \emph{complete mediation} --- every access to a protected resource must be check for appropriate authorization.  

Applying these principles to Facebook's SSO service, we define three important security properties: 1) \emph{authentication}
--- the application must verify the identity and signature of submitted credentials upon consumption to ensure protection against impersonation attacks as described in the illustrative example; 2) \emph{authorization} --- OAuth tokens bearing user
permission must stay within the session, ensuring no unsolicited permission leakage; and 3) \emph{association} --- the user identity of the application must match the identity of her associated OAuth tokens, ensuring consistencies between OAuth credentials and session identities.

\subsection{The Iterative Explication Process}

Explicating SDKs is a systematic investigation effort to explicitly document our knowledge about these modules and examine the knowledge against defined security goals.  Figure~\ref{fig:iterativeprocess} shows that this is an iterative process, in which we repeatedly refine our model and formally check if it is sufficient to establish the security properties or if additional assumptions are needed.  A failed check (i.e., a counterexample in the model) indicates either that our understanding of the actual systems needs to be revisited or that additional assumptions are indeed needed to ensure the desired security properties.  

\begin{figure}[hbt]
\centering
\includegraphics[width=0.9\textwidth]{figures/chapter3/explicationProcess.pdf}
\caption{Iterative process to uncover security-critical assumptions}
\label{fig:iterativeprocess}
\end{figure}

The outcome of the process is the assumptions we explicitly added to the model, as well as all other adjustments we made to the system behavior model in order to ensure all security properties.  These adjustments reflect bugs/flaws in real world systems and can be fixed based on our modifications to the model.  In Chapter~\ref{sec:explicating_discoveries}, we show that many of the uncovered assumptions can indeed be violated in realistic situations. 

\section{Semantic Modeling}
\label{sec:explicating_semantic_modeling}
In this chapter, we give an overview of the semantic modeling effort for the three SDKs we studied --- Facebook Connect PHP SDK, Microsoft Live Connect PHP SDK and Microsoft modern app client side SDK.  The resulting models are available at \url{https://github.com/sdk-security/}. They reflect a total of 12 person-months' effort in creating and refining the system models, however, part of this effort is spent to develop the idea of explication.  We believe this cost can get much lower as the researcher gets more experience about the explication process, or if the explication can utilize any inside information of either the IdP or the application platform provider.

\subsection{Modeling language}

To specify the semantics of the modules, we need to convert behaviors of the real-world system to a language that has a suitable formal analysis technology for verification.  In the first period of our investigation, we used Corral~\cite{Lal:2012:SRM:2362216.2362257}, a property checking tool that can perform bounded verification on a C program with embedded assertions.  Corral explores all possible execution paths within a bound to check if the assertions can be violated.  Later, we re-implemented all the models in Boogie~\cite{Boogie}, a language for describing proof obligations that can then be tested using an SMT solver, which allowed us to fully prove the desired properties.  This provides a higher assurance than the bounded verification done by Corral, but the basic ideas and approach are the same for both checking strategies.

Based on our experience with both formal analysis tools, we recommend that future explication process starts with a bounded model checker that works directly on C-like (or other well-understood languages) syntax, does not require loop invariants to be explicitly specified, and outputs human-friendly counterexample traces.  This significantly reduces the learning curve, which gives researchers more time to focus on behavior probing and converting added assumptions to real-world vulnerabilities.  However, after more experience are gained and when the model is relatively stable, switching to a theorem prover that can perform unbounded verification ensures the security properties cannot be violated with a much higher confidence.

For brevity, this section describes the Boogie version to explain our modeling.  The key Boogie language features necessary to understand this paper are:

\begin{itemize}

\item The * symbol represents a non-deterministic Boolean value. 
\item HAVOC v is a statement that assigns a non-deter-ministic value to variable v.
\item ASSERT(p) specifies an assertion that whenever the program gets to this line, p holds. 
\item ASSUME(p) instructs Boogie to assume that p holds whenever the program gets to this line. 
\item INVARIANT(p) specifies a loop invariant. Boogie checks if p is satisfied at the entry of the loop, and inductively prove p's validity after each iteration. 

\end{itemize}

If Boogie fails to prove an assertion or an invariant, it reports a counter-example. This leads us to refine the model, and adding assumptions when necessary. 

\subsection{Modeling Concrete Modules}

Concrete modules do not have any non-determinism. The key aspects of building semantic models for the concrete modules are summarized below.

\shortsection{Data types}  The basic data types in the models are integers and several types for enumerables.  We also define \code{struct} and \code{array} over the basic types.  In the actual systems, the authentication logic is constructed using string operations such as concatenation, tokenization, equality comparison, and name/value pair parsing.  We found that most string values can be modeled into integers without losing their relevant security logic representation, except those of domain names and user names, which we canonicalize as Alice (the victim), Mallory (the adversary), foo.com (the web application developer), and etc.  It is important that we limit the data types used in the model to maintain compatibility with the theorem prover and improve performance of the model checker.

\shortsection{SDKs}  The SDKs we studied are of moderate size (all under 2000 lines) and their source code are all published in the public.  They were implemented in HTML, JavaScript and PHP, so we first translate the SDKs function-by-function into the modeling language.  We do this translation manually, and although this process can likely be automated by program language tools, they lack of the functionality to abstract data structures and omit security-irrelevant details such as GUI manipulation and networking code.

\lstinputlisting[caption={Example Facebook PHP SDK code},label={lst:exampleFacebookPHPSDKCode}]{listings/php_model.php}
\lstinputlisting[caption={Example Facebook PHP SDK model},label={lst:exampleFacebookPHPSDKModel}]{listings/php_model.bgl}

For example, Listing~\ref{lst:exampleFacebookPHPSDKCode},~\ref{lst:exampleFacebookPHPSDKModel} show two functions in the Facebook PHP SDK and their corresponding Boogie models. For function \code{getUserFromAvailableData}, the changes are essentially line-by-line translations with objects converted to simple data types in a straightforward fashion.  For \code{getLogoutUrl}, the PHP code performs a string operation and returns a string.  Our Boogie translation in this case is not obviously line-by-line.  For example, our procedure returns a four-element vector instead of a string.  The PHP function calls \code{getUrl} and \code{array\_merge}, which concatenate substrings, therefore, are implicitly modeled by the four-element return vector. 

\shortsection{Underlying system layer}  Unlike the SDK, which is simple enough to model completely, the identity provider, client runtime, and server runtime are very complex and often do not even have source code available.  Completely modeling every detail of these systems is infeasible, but our analysis depends on developing suitable models of them.  To this end, we try to reconstruct the model by observing and probing the behavior of black-box components.  

Particularly, the identity provider responds differently to different input arguments and various app settings in its web portal.  Each identity provider has a web page for app developers to tweak a number of settings, such as app ID, app secret, service website domain, and return URL.  Many of these settings are critical for the identity provider's behavior.  Further, different inputs to the provided APIs cause different responses.  Because we do not have the source code for the identity providers, we probe these behaviors by constructing different requests and app settings, and monitoring the responses using a proxy server.  For example, the Microsoft Live Connect API dialog\_permissions\_request(), RST2\_srf() and oauth20\_ authorize\_srf() models involved 11, 8 and 6 if-statements respectively, to describe different behaviors we observed in the probing process.  Similarly, for client runtime we set up different parameters to call platform APIs defined in Windows 8 modern apps SDK and observe their return values.

\subsection{Modeling Abstract Modules}

The abstract modules interacts with the concrete modules in a non-deterministic manner.  It includes both the benign application and adversary controlled resources.  

\shortsection{Non-deterministic Calls} The key attributes of a model for an abstract module is to be able to exhibit non-deterministic behaviors.  To this end, we put the \code{HAVOC} statement, which generates a non-deterministic value inside a \code{switch} statement, with possible actions inside each \code{case} statement.  In the execution of the formal analysis tools, the symbolic values will be automatically assigned to violate any assertion if possible.  This part is not new to the model checking community, however, the situation is more complicated here as the benign application will need to be `reasonable' and follow the documented guidelines.  For example, we assume the developers never send out its app secret intentionally to the adversary.  For the guidelines, we exercise caution to read and enforce the guidelines on the switch statements.  Note that under-restriction is always better than over-restriction, as the latter will cause the symbolic execution engine to miss possible implicit assumptions. 

\shortsection{Knowledge Pool}  For the adversary, its behavior is not restricted by the developer guide; however, every call it makes will be require to supply meaningful parameters.  We introduce the concept of \emph{knowledge pool}, which models the adversary's current knowledge as the test harness runs.  Different types of knowledge, such as \emph{access\_token}, \emph{Code}, and PHP session IDs, are explicitly differentiated.  An \code{AddKnowledge} function for each security-critical credential type is added as Mallory's capabilities.  Initially, the knowledge pool is populated with publicly available information, such as the benign application's app ID, as well as Mallory's own credentials to IdP and Foo application.  As the adversary makes calls, it adds all information returned by that call to its knowledge pool.  Subsequent calls non-deterministically select a set of parameters out of all applicable type in the knowledge pool.  Finally, we consider attacks that involve providing arguments of the incorrect type out of scope, e.g., giving a session ID to a function expecting an access\_token.

\shortsection{Test Harness}  Finally, to put everything together and complete the test harness, we use an outside-most loop and another non-deterministic switch statement that has a limited loop count depth for Corral, and an endless loop for the Boogie theorem prover.  The loop count represents the maximum steps allowed for Corral to explore counterexamples.  For theorem prover this is unnecessary since it verifies the model based on the loop's operational semantics and manually supplied loop invariants.  Inside the switch statement, each case can be an API call from Foo application, a Mallory's move from the user's device or their back-end server.  The entire process is shown in Figure~\ref{fig:testharness}.

\begin{figure}[hbt]
\centering
\includegraphics[width=0.7\textwidth]{figures/chapter3/testharness.pdf}
\caption{Test harness workflow}
\label{fig:testharness}
\end{figure}

\subsection{Constructing Assertions}
\label{explicating_constructing_assertions}
This Chapter describes how we use ASSERT statements to document and test the desired security properties, covering each of the security violations described in Chapter~\ref{sec:security_properties}. 

\shortsection{Authentication violation} An authentication violation occurs when an attacker acquires some knowledge that could be used to convince FooApp\textsubscript{S} that the knowledge holder is Alice.  A simple example is the case we described in Chapter~\ref{sec:explicating_illustrative_example}, in which the knowledge obtained is an \emph{access\_token}.  In addition, we also consider IdP-signed data such as Facebook's \emph{signed\_messages} or Live ID's authentication tokens.  

As an example of the assertions in the model, when a Facebook \emph{signed\_messages} k is added to the knowledge pool, we assert that

\fbox{\parbox[c][4em][c]{\textwidth}{
\code{k.user_ID != \_alice \&\& k.app\_ID != \_foo\_app\_ID	\&\& TokenRecordsOnIdP[k.token].user\_ID != \_alice}
}}

where TokenRecordsOnIdP represents IdP's database storing the records of \emph{access\_token}s.

\shortsection{Authorization violation} To detect authorization violations, we add ASSERT statements inside the Mallory knowledge pool.  For example, the assertion in function \code{AddKnowledge_Code} is:

\fbox{\parbox[c][4em][c]{\textwidth}{ASSERT(!(c.user\_ID == \_alice \&\& c.app\_ID == \_foo\_app\_ID))}}

This checks that the \emph{Code} added to the knowledge pool is not associated with Alice on FooApp, and similar assertions are added to other credential types.  The app secret is different from the above knowledge types, because it is tied to the app not the user.  Therefore, an assertion must be added that under no circumstances can an app secret be leaked to any party other than Foo and the IdP.

\shortsection{Association violation} At the return point of every web API on FooApp\textsubscript{S}, we need to ensure the correct association of the user ID, the permission (represented by an \emph{access\_token} or \emph{Code}), and the session ID.  This ensures that the three key variables of the session all involve the same user.

\section{Summary of explication discoveries}
\label{sec:explicating_discoveries}

We applied the explication process to the Facebook PHP SDK, Microsoft Live Connect SDK and Windows 8 Modern app SDK.  The Facebook PHP SDK is the only server-side SDK officially supported on Facebook developers website and is currently among the most widely used third-party SSO SDKs.  Facebook also has client SDKs for Android and iOS apps, which have many concepts similar to the PHP SDK, but we have not studied them in detail.  The Live Connect SDK is provided by Microsoft for developing metro apps that use Live ID as the identity provider.  The Windows 8 Modern app SDK is another necessary lower layer SDK to support metro apps to use OAuth-based authentication (IdP not limited to Microsoft).  

\subsection{Assumptions Uncovered}

The models resulting from our study formally capture what we learned about the SDKs and the systems. Our assumptions are specified in two ways: (1) all the ASSUME statements that we added; (2) when we need to assume particular program behaviors, such as a function call must always precede another, we model the behaviors accordingly, and add comment lines to state that the modeled behaviors are assumptions, rather than concrete facts.  All the assumptions are added in order to satisfy the assertions that described in Chapter~\ref{explicating_constructing_assertions}.

\shortsection{Verification}  After all the assumptions were added, the models were automatically verified by Corral with the bound set to 5, meaning that the depth counter of the main loop never exceeds 5 in the test harness (Figure~\ref{fig:testharness}).  Such a depth gives a reasonable confidence that the security properties are achieved by the models and the added assumptions: the properties could only be violated by attacks consisting of six or more steps. Running on a Windows server with two 2.67GHz processors and 32GB RAM, it took 11.0 hours to check the Facebook PHP SDK, 26.3 hours to check Live Connect SDK (Both verification require Windows 8 Modern app SDK as the underlying SDK).

\shortsection{Unbounded verification}  The verification being bounded is a limitation of the models built for Corral, so we subsequently re-implemented all three models in Boogie language.  As stated before, verification of Boogie models is not automatic.  It requires human effort to specify preconditions and post-conditions for procedures, as well as loop invariants.  The Boogie verifier checks that (1) every precondition is satisfied at the call site; (2) if all preconditions of the procedure are satisfied, then all the postconditions will be satisfied when the procedure returns; (3) every loop invariant holds before entering the loop, and if after an iteration it still holds.  By induction, the verified properties hold for an infinite number of iterations. Rewriting the three models in Boogie took 14 person-days of effort, including a significant portion on specifying appropriate loop invariants.  The Boogie modeling did not find any serious case missed in the Corral modeling, but provides a higher level of confidence for the verification.

\input{tables/explicating_critical_assumptions}

\shortsection{Mapping added assumptions to the real world}  We manually examined each assumption added to assess whether it could be violated in realistic exploits.  This effort requires thinking about how apps may be deployed and executed in real-world situations.  Table~\ref{tab:explicating_critical_assumptions} summarizes the assumptions uncovered by our study that appear to be most critical.  These assumptions can be violated in the real world, and the violations result in security compromises.  Based on our experience in communicating with SDK providers, finding realistic violating conditions is a crucial step to convincing them to treat the cases with high priority.  This step requires extensive knowledge about systems, and does not appear to be easily automated.  We describe these assumptions in more detail in Section~\ref{sec:explicating_exploit_opportunities}.  Table~\ref{tab:explicating_other_assumptions} lists some assumptions uncovered that, if violated, would also lead to security compromises.  But, unlike the assumptions in Table~\ref{tab:explicating_critical_assumptions}, we have not found compelling realistic exploits that violate these assumptions.  

\input{tables/explicating_other_assumptions}

\section{Exploit opportunities}
\label{sec:explicating_exploit_opportunities}

This Chapter explains how a real world attacker can exploit an application that is missing the critical assumptions in Table~\ref{tab:explicating_critical_assumptions}.  These facts show how the SDK's security assurance depends on actual system behaviors and app implementations, illustrating the importance of explicating the underlying assumptions upon which secure use of the SDK relies.  

\subsection{Facebook SDK}

Assumptions A1, A2, A3, and A6 listed in Table~\ref{tab:explicating_critical_assumptions} concern the Facebook PHP SDK.

\begin{figure}[hbt]
\centering
\includegraphics[width=0.9\textwidth]{figures/chapter3/facebookA1.pdf}
\caption{Facebook PHP SDK usage instructions}
\label{fig:facebookA1}
\end{figure}

\shortsection{Assumption A1}  This assumption states that the cookie associated with Alice's client must match Alice's session ID. Figure~\ref{fig:facebookA1} is a screenshot of the usage instructions given in the README file\footnote{Taken from \url{https://github.com/facebook/facebook-php-sdk/blob/master/readme.md}} in the Facebook PHP SDK.  It seems straightforward to understand: the first code snippet calls getUser to get the authenticated user ID; the second snippet demonstrates how to make an API call to retrieve further information; and the third snippet toggles between login and logout state, so that an authenticated session will get a logoutURL and an anonymous session will get a loginURL in the response.

The SDK's implementation for the getUser method is very simple. It calls the getUserFromAvailableData function shown in Listing~\ref{lst:exampleFacebookPHPSDKCode}.  There are two statements calling setPersistantData, which is to set a PHP session variable denoted as \_SESSION['user\_id'].  This action belongs to binding operations because it associates the user's identity with the session, which may affect the predicate that we define against association violations --- specifically, if Alice's user ID is assigned to the \_SESSION['user\_id'] of Mallory's session, it would allow Mallory to act on FooApp\textsubscript{S} as Alice.  Since the session ID is a cookie in the HTTP request, the assertion depends on how the client runtime handles cookies.  

Normally, because of the same-origin-policy of the client, cookies attached to one domain are not attached to another. However, the policy becomes interesting when we consider a cloud-hosting scenario.  In fact, Facebook's developer portal makes it very easy to deploy the application server on Heroku, a cloud platform-as-a-service.  Each service app runs in a subdomain under herokuapp.com (e.g., FooApp\textsubscript{S}'s subdomain runs as foo.herokuapp.com).  Of course, Mallory can similarly run a service on behalf of mallory.herokuapp.com.

The standard cookie policy for subdomains allows code on mallory.herokuapp.com to set a cookie for the parent domain herokuapp.com.  When the client makes a request to foo.herokuapp.com, the cookie will also be attached to the request. Therefore, if Alice's client visits the site mallory.herokuapp.com, Mallory will be able to make the client's cookie hold Mallory's session ID.  Thus, FooApp\textsubscript{S} incorrectly binds Alice's user ID to Mallory's session. 

In response to our report, Facebook developed a countermeasure for the SDK.  Instead of accepting an old session ID value in cookie, it always generates a new session ID (unknown to Mallory) every time a client is authenticated.  Facebook offered us a bounty three times the normal Bug Bounty amount for reporting this issue, as well as the same award each for Assumptions A2 and A3 discussed next. 

\shortsection{Assumption A2} This assumption is a case in which Corral actually discovered a valid path for violating an assertion completely unexpected to us.  The path indicated that if a PHP page on FooApp\textsubscript{S} only calls getUser (e.g., only has the first code snippet from Figure~\ref{fig:facebookA1}), Mallory is able to bind her user ID to Alice's session.  The consequence is especially damaging if the session's \emph{access\_token} is still Alice's.  Corral precisely suggested the possibility (see Table~\ref{tab:explicating_critical_assumptions}): if there is a \emph{signed\_request} containing Mallory's user ID, then the first setPersistentData call will be made, followed by a return.  The method sets \_SESSION['user\_id'] to Mallory's ID without calling getAccessToken, which would otherwise keep the \emph{access\_token} consistent with the user ID.  Therefore, the association between the user ID and the \emph{access\_token} could be incorrect. The session will operate as Mallory's account using Alice's \emph{access\_token}.  After investigating our report about this, Facebook decided to add checking code before processing the signed request to the SDK to avoid the need for this assumption.

\shortsection{Assumption A3} This assumption requires that any PHP page that includes the first and fourth snippet in Figure~\ref{fig:facebookA1} must also include the second snippet in between.  This assumption is discovered when we model getAccessToken, as shown in Listing~\ref{lst:getAccessToken}.  We realized that in Facebook's authentication mechanism there are two subcategories of access token: `user' \emph{access\_token}, as described earlier in this dissertation, and `application' access token, which is provided to a web service for a number of special purposes, such as publishing instances of `secure Open Graph actions'.  In fact, the app secret can be derived solely from the application access token, so it is a serious authorization violation if Mallory can obtain it. 

\lstinputlisting[caption={Facebook PHP SDK getAccessToken function},label={lst:getAccessToken}]{listings/getAccessToken.js}

Method getLogoutUrl in the fourth snippet in Figure~\ref{fig:facebookA1} constructs a URL to send back to the client.  The URL contains the result of getAccessToken.  To obtain the application access token, Mallory only needs to send a request that hits a failure condition of getUserAccessToken, which prevents \code{\$this->accessToken} from being overwritten in the bold line in Listing~\ref{lst:getAccessToken}.  We confirmed that this can be done by supplying an invalid \emph{Code}in the request. 

Interestingly, getAccessToken is also called by getUser in the first snippet in Figure~\ref{fig:facebookA1}.  If a PHP page includes the second snippet after the first, the supplied access token will be used to call a REST API.  When it is an application access token, the API will raise an exception, which foils the exploit.  That is why the second snippet is required before the fourth.

In response to our report on this issue, Facebook modified the SDK so that getLogoutUrl now calls getUserAccessToken instead of getAccessToken, thus avoiding the need for developers to satisfy this assumption.

\shortsection{Assumption A6}  This assumption requires that the user on FooApp\textsubscript{C} should not be Mallory.  Otherwise, Mallory would be able to associate its \emph{access\_token} and user id with Alice's session.  This is in fact requiring the application server to thwart any adversary performing session fixation attack by correctly implementing the cross-site request forgery defense.  Moreover, this association violation can be particularly damaging when the service app has its own credential system, and supports linking a Facebook ID to Aliceâ€™s password-protected account.  Once the linking can be done in the session, Mallory will be able to sign into Alice's account using Mallory's Facebook ID.  We confirmed that among the 21 applications displayed on Facebook showcase page, 14 service apps which violate the assumption, 6 of them support linking, and thus allowing Mallory to login as Alice in the future.  We reported this issue to Facebook, who undertook efforts of notifying app and website developers.

\subsection{Microsoft Live Connect}

\shortsection{Assumption A4}  The sample code given by Microsoft Live Connect documentation is essentially a program skeleton, with comment blocks for app developers to implement.  The core of the problem lies in the following function, whose implementation is empty except for a comment:

\lstinputlisting[caption={Microsoft Live Connect PHP SDK saveRefreshToken function},label={lst:saveRefreshToken}]{listings/saveRefreshToken.php}

This is precisely what we call a binding operation. The refresh token is the input parameter, but it is not clear where the user id comes from.  Within the scope of this function, the straightforward way to obtain this ID is from a cookie called AUTHCOOKIE, which contains the user's Live ID.  However, if the application is implemented this way, the SDK's logic is not sufficient to ensure that Alice's refresh token is always associated with her user ID.  In fact, we show that Alice's refresh token will be associated with Mallory's user ID if the attacker lures Alice (who has already logged into her Live Connect account) to visit a carefully crafted page.  This will further lead to Alice's long-lived \emph{access\_token} and \emph{authentication\_token} be exposed to Mallory.

We sent this proof-of-concept exploit to Microsoft.  The team replied us and the comment in saveRefreshToken function has been revised to ``save the refresh token and associate it with the user identified by your site credential system.''  This change was also made in the ASP.NET version of the sample code.

\subsection{Windows 8 Modern app SDK}

\shortsection{Assumption A5}  Windows 8 Modern app SDK is used by Windows 8 app developers who wishes to integrate OAuth-based identity providers.  In the SDK, the function of interest here is authenticateAsync.  Figure~\ref{fig:authenticateAsync} illustrates the data passing through this function when the app requests an \emph{access\_token}.  The key observation is that the client does not conform to the same-origin policy, because the 302 response is in the context of https://facebook.com, while on Windows 8, an app runs in its own specialized domain, ms-appx://packageID.  Without the same-origin policy, we were unable to see why Alice's \emph{access\_token} for FooApp is guaranteed to be passed to FooApp\textsubscript{C}, not MalApp\textsubscript{C}.  To test this, we implemented a successful proof-of-concept attack to obtain Alice's \emph{access\_token}.

\begin{figure}[hbt]
\centering
\includegraphics[width=0.6\textwidth]{figures/chapter3/authenticateAsync.pdf}
\caption{The data flow of authenticateAsync function in Modern app SDK}
\label{fig:authenticateAsync}
\end{figure}
 
We reported this finding to Microsoft and Facebook.  Microsoft considered it ``a shortcoming of the OAuth protocol and not specific to our implementation.''.  Facebook pointed out that when authenticateAsync is called, an embedded browser window (usually called a WebView) is always prompted for Facebook password.  This lowered the severity of the attack.  We consider this a shaky security basis: if authenticateAsync allows a user to login automatically or with one click without using a password in the future, the basis will become invalid. 

We investigated how SDKs on other platforms handle the data passing, and found a similar issue with the Facebook SDK for Android.  However, on Android, there is a mechanism to skip the password prompt to get the \emph{access\_token} automatically. In response to our report, Facebook is developing a fix for its Android SDK.

\subsection{Testing Real-world Applications}
\label{sec:explicating_test}

To see if the discovered implicit assumptions are indeed likely to be missed by real-world applications, we selected three assumptions that are amenable to checking --- A1, A6 in Table~\ref{tab:explicating_critical_assumptions} and the one in the illustrative example in Chapter~\ref{sec:explicating_illustrative_example} (denoted as assumption IE).  We subsequently describe our test application selection, testing approach and results.

\shortsection{Test application pool} we downloaded high-ranked applications from Windows 8 Store for assumption IE and did Google queries for relevant keywords for assumption A1 and A6.  We manually confirm that the test applications supports Facebook/Microsoft Live Connect login.

\shortsection{Testing approach}  Checking applications requires the ability to manipulate traffic to and from the IdP and the testing application's server.  We use the Fiddler proxy~\cite{Fiddler} which may act as a Man-In-The-Middle and support modification to decrypted SSL traffic.  For assumption IE, we manually login to target application through SSO as Mallory, requests an \emph{access\_token} Facebook, however, before forwarding this to the application, we replace it with Alice's \emph{access\_token} intended for another malicious application and check if the impersonation attack has succeeded.  This process is described in more details later in Chapter~\ref{sec:ssoscan_manual_example}.  For assumption A1, if the testing application server's hostname is foo.a.com, we assume the proxy controls another hostname mallory.a.com.  The test follows the steps described earlier in this section.  Eventually the proxy checks if the authentication is successful, but the associated session ID is identical to that of Malloryâ€™s session on foo.a.com.  For assumption A6, the proxy observes the HTTP request that FooApp\textsubscript{C} sends to Facebook.  It attempts to locate a field named \emph{state}, which is an parameter supported by Facebook to prevent request forgery for login.  The proxy then replaces the OAuth credential and the state field with the ones that Mallory's session owns.  After sending the request, the proxy checks whether Mallory can associate her Facebook ID with Alice's session, and reports a violation if it sees a successful server response.  

\input{tables/explicating_test_results}

\shortsection{Test results} Table~\ref{tab:explicating_test_results} shows the test results.  The affected application percentages are very high for all vulnerabilities.  We think this might be due to several reasons.  For assumption IE, as of the time we carried out the tests, Windows 8 Store was just opened to public and it is conceivable that applications are less mature.  For assumption A1, all applications using Facebook PHP SDK that is hosted on a cloud platform would be affected, unless the developers included additional logic to defeat the attack (intentionally or unintentionally).  For A6, it may appear to an average developer that the parameter \emph{state} has nothing to do with the SSO functionality and can be safely omitted, therefore causing many vulnerable cases.